---
title: VPC
icon: material/bucket
---
# Amazon S3 Comprehensive Guide

Amazon Simple Storage Service (S3) is a scalable object storage service used for backup, archiving, application data, and more. This guide covers S3 fundamentals, configuration best practices, and useful AWS CLI commands.

---

## What is Amazon S3?

Amazon S3 is an object storage service that offers industry-leading scalability, data availability, security, and performance. It is used to store and retrieve any amount of data from anywhere on the web.

## Key Concepts

- **Buckets**: Containers for storing objects (files).
- **Objects**: Files and metadata stored in buckets.
- **Keys**: Unique identifiers for objects within a bucket.
- **Regions**: Physical locations where buckets reside.
- **Storage Classes**: Different cost and performance options (e.g., Standard, Intelligent-Tiering, Glacier).

## Bucket Usage Types
Amazon S3 buckets are not categorized into strict "types" by AWS, but their usage is often defined by how they are configured and the storage class of the objects they contain. The main distinctions are:

- **General Purpose Buckets**: Used for storing any type of object, including documents, images, backups, and application data.
- **Static Website Hosting Buckets**: Configured to serve static web content directly over HTTP. These buckets require public read access and specific configuration for index and error documents.
- **Logging Buckets**: Dedicated to storing server access logs generated by other S3 buckets.
- **Replication Buckets**: Serve as the source or destination for cross-region or same-region replication, supporting disaster recovery and compliance.
- **Archive Buckets**: Primarily store objects in archival storage classes such as S3 Glacier or S3 Glacier Deep Archive for long-term retention.

While these are common usage patterns, any S3 bucket can be configured with features like versioning, encryption, object lock, and lifecycle policies to suit specific requirements.




## Naming Rules
When creating an S3 bucket, follow these naming rules:

- Bucket names must be globally unique across all AWS accounts.
- Names must be between 3 and 63 characters in length.
- Only lowercase letters, numbers, hyphens (`-`), and periods (`.`) are allowed.
- Names must start and end with a letter or number.
- No uppercase letters or underscores.
- Cannot be formatted as an IP address (e.g., `192.168.1.1`).
- Avoid using consecutive periods or dashes next to periods (e.g., `my..bucket`, `my.-bucket`).
- For best compatibility, use only lowercase letters, numbers, and hyphens.
- Cannot start with: xn--, sthree-, amzn-s3-demo-

See the [official naming guidelines](https://docs.aws.amazon.com/AmazonS3/latest/userguide/bucketnamingrules.html) for more details.


## Limitations
Amazon S3 is highly scalable and reliable, but there are important limitations to consider:

- **Object Size Limits**: Maximum object size is 5 TB. Single PUT uploads are limited to 5 GB; larger objects require multipart upload.
- **Bucket Limits**: Each AWS account can create up to 100 buckets by default.
- **Request Rate Limits**: While S3 supports high request rates, extremely high rates may require key name optimization to avoid throttling.
- **Eventual Consistency**: Some operations (e.g., overwrite PUTS and DELETES) may exhibit eventual consistency.
- **No Native File System Semantics**: S3 is object storage, not a traditional file systemâ€”no support for file locking or POSIX permissions.
- **Object Immutability**: Objects cannot be modified in place; updates require uploading a new version.
- **Metadata Size Limit**: User-defined metadata per object is limited to 2 KB.
- **No Transactional Operations**: S3 does not support multi-object transactions or atomic renames.
- **Cost Considerations**: Frequent access, small object sizes, or high request rates can increase costs.


For additional details visit: https://docs.aws.amazon.com/general/latest/gr/s3.html#limits_s3

## Directory Buckets

**Directory buckets** are a new S3 bucket type designed to support the S3 Express One Zone storage class, providing high-throughput and low-latency access for workloads that require fast, parallel operations (such as big data analytics and AI/ML). Unlike standard S3 buckets, directory buckets use a hierarchical namespace similar to a file system, allowing for efficient organization and retrieval of objects.

### Key Features

- **Hierarchical Namespace**: Supports directories and subdirectories, enabling file system-like organization.
- **High Performance**: Optimized for workloads needing very high request rates and low latency.
- **Single Availability Zone**: Data is stored in a single AZ, so it's best for non-critical or easily re-creatable data.
- **S3 Express One Zone Only**: Directory buckets are only available with the S3 Express One Zone storage class.

### Use Cases

- High-performance analytics workloads
- Machine learning pipelines
- Temporary storage for data processing jobs

### Example CLI Command

Create a directory bucket (requires AWS CLI v2.15.0+):

```sh
aws s3control create-bucket --bucket my-directory-bucket --bucket-type directory
```

> **Note:** Directory buckets have unique naming and access requirements. See the [official documentation](https://docs.aws.amazon.com/AmazonS3/latest/userguide/directory-buckets.html) for details.


## Configuration Best Practices

#### Bucket Naming
- Use DNS-compliant, globally unique names.
- Avoid using sensitive information in bucket names.

#### Security
- **Enable Bucket Versioning**: Protects against accidental deletions and overwrites.
- **Enable Server-Side Encryption**: Use S3-managed keys (SSE-S3) or AWS KMS (SSE-KMS).
- **Block Public Access**: Use S3 Block Public Access settings to prevent unintended exposure.
- **Use IAM Policies**: Grant least privilege access to users and applications.
- **Enable Access Logging**: Track requests for auditing and troubleshooting.

#### Data Management
- **Lifecycle Policies**: Automatically transition objects to cheaper storage classes or delete them after a set period.
- **Replication**: Enable cross-region replication for disaster recovery.
- **Object Lock**: Use for regulatory compliance and data retention.

#### Performance
- **Prefix Optimization**: Distribute object keys across multiple prefixes for higher request rates.
- **Multipart Uploads**: Use for large files to improve upload reliability and speed.

#### Cost Optimization
- **Monitor Usage**: Use AWS Cost Explorer and S3 Storage Lens.
- **Choose Appropriate Storage Classes**: Match storage class to access patterns.
- **Delete Unused Data**: Regularly review and remove unnecessary objects.

#### Configuration Options

Below are key S3 configuration options, including details on storage classes, pricing, and use cases:

**Versioning**
- **Description**: Maintains multiple variants of an object in the same bucket.
- **Use Case**: Protects against accidental deletions or overwrites.
- **How to Enable**: Can be enabled per bucket; once enabled, cannot be disabled (only suspended).

**Server-Side Encryption**
- **Description**: Encrypts data at rest using S3-managed keys (SSE-S3), AWS KMS keys (SSE-KMS), or customer-provided keys (SSE-C).
- **Use Case**: Ensures data confidentiality and compliance.

**Object Lock**
- **Description**: Prevents objects from being deleted or overwritten for a fixed time or indefinitely.
- **Use Case**: Regulatory compliance, legal holds, and data retention.

**Cross-Region Replication (CRR)**
- **Description**: Automatically replicates objects to a bucket in another AWS region.
- **Use Case**: Disaster recovery, latency reduction, compliance.

**Lifecycle Policies**
- **Description**: Automates transitions between storage classes or object expiration.
- **Use Case**: Cost optimization by moving infrequently accessed data to cheaper storage.

**Access Logging**
- **Description**: Records requests made to your S3 bucket.
- **Use Case**: Security auditing, access monitoring, troubleshooting.

**Requester Pays**
- **Description**: Shifts data transfer and request costs to the requester rather than the bucket owner.
- **Use Case**: Data sharing scenarios where consumers pay for access.

**Event Notifications**
- **Description**: Triggers notifications (SNS, SQS, Lambda) on object events (e.g., upload, delete).
- **Use Case**: Automate workflows, trigger processing pipelines.

---

### S3 Storage Classes

| Storage Class                | Pricing (per GB/month)\* | Durability & Availability         | Use Case                                      |
|------------------------------|--------------------------|-----------------------------------|------------------------------------------------|
| **S3 Standard**              | ~$0.023                  | 99.999999999% durability, 99.99% availability | Frequently accessed data, active content       |
| **S3 Intelligent-Tiering**   | ~$0.023 + monitoring fee | Same as Standard                  | Data with unknown or changing access patterns  |
| **S3 Standard-IA**           | ~$0.0125                 | 99.9% availability                | Infrequently accessed, but rapidly retrievable |
| **S3 One Zone-IA**           | ~$0.01                   | 99.5% availability, single AZ     | Infrequent access, non-critical data           |
| **S3 Glacier Instant Retrieval** | ~$0.004                | 99.999999999% durability          | Archive, instant access needed                 |
| **S3 Glacier Flexible Retrieval** | ~$0.0036              | 99.999999999% durability          | Archive, minutes to hours retrieval            |
| **S3 Glacier Deep Archive**  | ~$0.00099                | 99.999999999% durability          | Long-term archive, hours retrieval             |
| **S3 Reduced Redundancy (deprecated)** | N/A             | Lower durability                  | Not recommended for new workloads              |

\*Pricing varies by region. See [S3 Pricing](https://aws.amazon.com/s3/pricing/) for details.

#### Storage Class Use Cases

- **S3 Standard**: Active content, websites, mobile apps, big data analytics.
- **S3 Intelligent-Tiering**: Data with unpredictable or changing access patterns.
- **S3 Standard-IA**: Backups, disaster recovery, long-term storage with occasional access.
- **S3 One Zone-IA**: Secondary backups, easily re-creatable data.
- **S3 Glacier Instant Retrieval**: Archives needing immediate access (e.g., medical images).
- **S3 Glacier Flexible Retrieval**: Long-term archives, compliance data, digital preservation.
- **S3 Glacier Deep Archive**: Regulatory archives, rarely accessed data, digital preservation.


For the latest and most detailed limitations, refer to the [S3 documentation](https://docs.aws.amazon.com/AmazonS3/latest/userguide/limits.html).

## Common AWS CLI Commands

### Prerequisites

Install the AWS CLI and configure your credentials:

```sh
aws configure
```

### Bucket Operations

**Create a bucket:**
```sh
aws s3 mb s3://my-bucket --region us-east-1
```

**List all buckets:**
```sh
aws s3 ls
```

**Delete a bucket:**
```sh
aws s3 rb s3://my-bucket --force
```

### Object Operations

**Upload a file:**
```sh
aws s3 cp myfile.txt s3://my-bucket/
```

**Download a file:**
```sh
aws s3 cp s3://my-bucket/myfile.txt ./
```

**Sync a local directory to a bucket:**
```sh
aws s3 sync ./local-folder s3://my-bucket/remote-folder
```

**List objects in a bucket:**
```sh
aws s3 ls s3://my-bucket/
```

### Security and Management

**Enable versioning:**
```sh
aws s3api put-bucket-versioning --bucket my-bucket --versioning-configuration Status=Enabled
```

**Enable default encryption:**
```sh
aws s3api put-bucket-encryption --bucket my-bucket --server-side-encryption-configuration 'ServerSideEncryptionConfiguration=[{"ServerSideEncryptionByDefault":{"SSEAlgorithm":"AES256"}}]'
```

**Block all public access:**
```sh
aws s3api put-public-access-block --bucket my-bucket --public-access-block-configuration BlockPublicAcls=true,IgnorePublicAcls=true,BlockPublicPolicy=true,RestrictPublicBuckets=true
```

## References

- [Amazon S3 Documentation](https://docs.aws.amazon.com/s3/index.html)
- [AWS CLI Command Reference](https://docs.aws.amazon.com/cli/latest/reference/s3/index.html)
- [S3 Best Practices](https://aws.amazon.com/premiumsupport/knowledge-center/s3-best-practices/)

